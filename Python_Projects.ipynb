{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1B-PdaWTEOg3zW6Oc_znLwL0e6PzOhnjP",
      "authorship_tag": "ABX9TyPvfosCbhF4xIENKAgfYBbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmairam/Python-Relearn-2026/blob/main/Python_Projects.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Smart Text Cleaner & Analyzer**"
      ],
      "metadata": {
        "id": "U6Rk9lCXD5pC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line **content.translate(str.maketrans('', '', string.punctuation))** is used for cleaning text by removing all punctuation. Here's a breakdown:\n",
        "\n",
        "**string.punctuation:** This is a string containing all standard punctuation characters (e.g., !\"#$%&'()*+,-./:;<=>?@[\\]^_{|}~`).\n",
        "\n",
        "**str.maketrans('', '', string.punctuation):** This static method creates a translation table. In this case, the first two arguments are empty strings, meaning no characters will be mapped to others (replaced). The third argument, string.punctuation, specifies characters to be deleted during the translation process.\n",
        "\n",
        "**content.translate(...):** This string method applies the created translation table to the content string. As a result, all punctuation characters present in content will be removed.\n"
      ],
      "metadata": {
        "id": "XY5nu6NdKmB9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FS8fnCXDbyC",
        "outputId": "630e9be5-dd3b-49d5-e9a1-3bd16f377598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis results written to '/content/sample_data/analyzed_text.txt'\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def fileAnalyzer(filename, top_n, output_filename=None):\n",
        "  try:\n",
        "    with open(filename, 'r') as f:\n",
        "      text = f.read()\n",
        "  except FileNotFoundError:\n",
        "    if output_filename:\n",
        "      with open(output_filename, 'w') as out_f:\n",
        "        out_f.write(f\"Error: The file '{filename}' was not found.\\n\")\n",
        "    else:\n",
        "      print(f\"Error: The file '{filename}' was not found.\")\n",
        "    return\n",
        "\n",
        "  # Clean the text: convert to lowercase and remove punctuation\n",
        "  content = text.lower()\n",
        "  content = content.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  words = content.split()\n",
        "  unique_words = set(words)\n",
        "  sentences = text.split('.')\n",
        "  # Use Counter to efficiently count occurrences\n",
        "  word_counts = Counter(words)\n",
        "\n",
        "  # Get the top N most common words\n",
        "  top_keywords = word_counts.most_common(top_n)\n",
        "  base_filename = os.path.basename(filename).split('/')[-1]\n",
        "\n",
        "  output_lines = []\n",
        "  output_lines.append(f\"Total words: {len(words)}\\n\")\n",
        "  output_lines.append(f\"Unique words: {len(unique_words)}\\n\")\n",
        "  output_lines.append(f\"Total sentences: {len(sentences)}\\n\")\n",
        "  output_lines.append(f\"Top {top_n} keywords in '{base_filename}':\\n\")\n",
        "  # Print the keywords and their counts using f-strings\n",
        "  for word, count in top_keywords:\n",
        "    output_lines.append(f\"â€¢ '{word}': {count} occurrences\\n\")\n",
        "\n",
        "  if output_filename:\n",
        "    with open(output_filename, 'w') as out_f:\n",
        "      out_f.writelines(output_lines)\n",
        "    print(f\"Analysis results written to '{output_filename}'\")\n",
        "  else:\n",
        "    for line in output_lines:\n",
        "      print(line.strip())\n",
        "\n",
        "# If sample_text file is not available, look in 2026 Python Projects Folder in Drive\n",
        "fileAnalyzer('/content/drive/MyDrive/2026 Python Projects/sample_text.txt', 5, '/content/sample_data/analyzed_text.txt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ahLvURkHeMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}